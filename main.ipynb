{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import csv\n",
    "from enum import Enum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our Hyperparameters, Global Constants, and Config Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 0.005\n",
    "INITIAL_WEIGHT = 0\n",
    "INITIAL_BIAS = 0\n",
    "\n",
    "#                          |     0      |     1   |    2  |   3  |   4  |    5   |    6   |     7   |    8  |    9   |      10   |\n",
    "COLUMNS = Enum('COLUMNS', ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'])\n",
    "\n",
    "# CONFIG\n",
    "DATASET_NAME = \"train.csv\"\n",
    "# MUST BE ONE OF THESE VALUES: PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "TRAINING_COLUMN = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will read the data into a polars dataframe and then return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_format_data(filename):\n",
    "    read_data = pl.read_csv(\"data/\" + filename)\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "   \n",
    "    m = len(x)\n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def compute_gradient(x, y, w, b):\n",
    "    m = len(x)\n",
    "    w_g = 0\n",
    "    d_g = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        pred = w * x[i] + b\n",
    "        w_df = (pred - y[i]) * x[i]\n",
    "        d_df = (pred - y[i])\n",
    "        w_g += w_df\n",
    "        d_g += d_df\n",
    "    w_g /= m\n",
    "    d_g /= m\n",
    "\n",
    "    return w_g, d_g\n",
    "\n",
    "def gradient_descent(x, y, w_initial, b_initial, num_epochs):\n",
    "    w = w_initial\n",
    "    b = b_initial\n",
    "    for i in range(num_epochs):\n",
    "        w_g, d_g = compute_gradient(x, y, w, b)\n",
    "        w = w - LEARNING_RATE * w_g\n",
    "        b = b - LEARNING_RATE * d_g\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            loss = compute_cost(x, y, w, b)\n",
    "            print(f\"Run: {i} Loss: {loss}\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can actually run our model and get an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Loss: 0.18844119660200134\n",
      "Run: 10 Loss: 0.1642418756994117\n",
      "Run: 20 Loss: 0.15210268065444796\n",
      "Run: 30 Loss: 0.1459242799053586\n",
      "Run: 40 Loss: 0.14269294582492908\n",
      "Run: 50 Loss: 0.14091956283254234\n",
      "Run: 60 Loss: 0.13986833373301794\n",
      "Run: 70 Loss: 0.13917567977765635\n",
      "Run: 80 Loss: 0.13866193733506377\n",
      "Run: 90 Loss: 0.1382383163015593\n",
      "Run: 100 Loss: 0.1378609277989062\n",
      "Run: 110 Loss: 0.13750806903515927\n",
      "Run: 120 Loss: 0.13716899964255003\n",
      "Run: 130 Loss: 0.13683839600989198\n",
      "Run: 140 Loss: 0.1365136111396433\n",
      "Run: 150 Loss: 0.13619332072832752\n",
      "Run: 160 Loss: 0.13587685418661188\n",
      "Run: 170 Loss: 0.13556386409144314\n",
      "Run: 180 Loss: 0.13525416285913097\n",
      "Run: 190 Loss: 0.1349476420430703\n",
      "Run: 200 Loss: 0.13464423245678572\n",
      "Run: 210 Loss: 0.1343438844689364\n",
      "Run: 220 Loss: 0.1340465582654075\n",
      "Run: 230 Loss: 0.13375221903620768\n",
      "Run: 240 Loss: 0.133460834595777\n",
      "Run: 250 Loss: 0.13317237420560807\n",
      "Run: 260 Loss: 0.13288680799101377\n",
      "Run: 270 Loss: 0.13260410665145678\n",
      "Run: 280 Loss: 0.13232424131593534\n",
      "Run: 290 Loss: 0.13204718347007352\n",
      "Run: 300 Loss: 0.13177290491862997\n",
      "Run: 310 Loss: 0.13150137776556808\n",
      "Run: 320 Loss: 0.1312325744027683\n",
      "Run: 330 Loss: 0.13096646750305013\n",
      "Run: 340 Loss: 0.13070303001533307\n",
      "Run: 350 Loss: 0.1304422351608734\n",
      "Run: 360 Loss: 0.13018405643003422\n",
      "Run: 370 Loss: 0.12992846757934412\n",
      "Run: 380 Loss: 0.12967544262870445\n",
      "Run: 390 Loss: 0.12942495585869762\n",
      "Run: 400 Loss: 0.1291769818079263\n",
      "Run: 410 Loss: 0.12893149527042358\n",
      "Run: 420 Loss: 0.1286884712930824\n",
      "Run: 430 Loss: 0.12844788517310293\n",
      "Run: 440 Loss: 0.12820971245549823\n",
      "Run: 450 Loss: 0.12797392893059453\n",
      "Run: 460 Loss: 0.1277405106315771\n",
      "Run: 470 Loss: 0.12750943383204824\n",
      "Run: 480 Loss: 0.12728067504361806\n",
      "Run: 490 Loss: 0.1270542110135174\n",
      "Run: 500 Loss: 0.12683001872223382\n",
      "Run: 510 Loss: 0.12660807538117222\n",
      "Run: 520 Loss: 0.12638835843033522\n",
      "Run: 530 Loss: 0.1261708455360388\n",
      "Run: 540 Loss: 0.1259555145886258\n",
      "Run: 550 Loss: 0.1257423437002349\n",
      "Run: 560 Loss: 0.12553131120257227\n",
      "Run: 570 Loss: 0.1253223956447005\n",
      "Run: 580 Loss: 0.1251155757908682\n",
      "Run: 590 Loss: 0.12491083061834005\n",
      "Run: 600 Loss: 0.12470813931527776\n",
      "Run: 610 Loss: 0.12450748127860878\n",
      "Run: 620 Loss: 0.12430883611192944\n",
      "Run: 630 Loss: 0.1241121836234526\n",
      "Run: 640 Loss: 0.1239175038239348\n",
      "Run: 650 Loss: 0.12372477692464862\n",
      "Run: 660 Loss: 0.1235339833353824\n",
      "Run: 670 Loss: 0.12334510366243612\n",
      "Run: 680 Loss: 0.12315811870665219\n",
      "Run: 690 Loss: 0.12297300946146898\n",
      "Run: 700 Loss: 0.1227897571109912\n",
      "Run: 710 Loss: 0.12260834302806166\n",
      "Run: 720 Loss: 0.12242874877238713\n",
      "Run: 730 Loss: 0.12225095608865431\n",
      "Run: 740 Loss: 0.12207494690466822\n",
      "Run: 750 Loss: 0.12190070332953234\n",
      "Run: 760 Loss: 0.12172820765181427\n",
      "Run: 770 Loss: 0.12155744233775179\n",
      "Run: 780 Loss: 0.1213883900294672\n",
      "Run: 790 Loss: 0.12122103354321166\n",
      "Run: 800 Loss: 0.12105535586760971\n",
      "Run: 810 Loss: 0.12089134016192973\n",
      "Run: 820 Loss: 0.12072896975438004\n",
      "Run: 830 Loss: 0.12056822814040702\n",
      "Run: 840 Loss: 0.12040909898102224\n",
      "Run: 850 Loss: 0.12025156610113519\n",
      "Run: 860 Loss: 0.12009561348791452\n",
      "Run: 870 Loss: 0.1199412252891627\n",
      "Run: 880 Loss: 0.11978838581169651\n",
      "Run: 890 Loss: 0.11963707951975812\n",
      "Run: 900 Loss: 0.11948729103343929\n",
      "Run: 910 Loss: 0.11933900512710091\n",
      "Run: 920 Loss: 0.11919220672784908\n",
      "Run: 930 Loss: 0.11904688091398839\n",
      "Run: 940 Loss: 0.11890301291350233\n",
      "Run: 950 Loss: 0.11876058810256326\n",
      "Run: 960 Loss: 0.11861959200404287\n",
      "Run: 970 Loss: 0.11848001028603086\n",
      "Run: 980 Loss: 0.11834182876038699\n",
      "Run: 990 Loss: 0.11820503338130123\n",
      "Run: 1000 Loss: 0.11806961024385958\n",
      "Run: 1010 Loss: 0.1179355455826286\n",
      "Run: 1020 Loss: 0.11780282577026853\n",
      "Run: 1030 Loss: 0.1176714373161356\n",
      "Run: 1040 Loss: 0.1175413668649149\n",
      "Run: 1050 Loss: 0.11741260119526642\n",
      "Run: 1060 Loss: 0.11728512721847445\n",
      "Run: 1070 Loss: 0.11715893197712386\n",
      "Run: 1080 Loss: 0.11703400264377689\n",
      "Run: 1090 Loss: 0.11691032651967219\n",
      "Run: 1100 Loss: 0.1167878910334382\n",
      "Run: 1110 Loss: 0.11666668373980905\n",
      "Run: 1120 Loss: 0.11654669231835761\n",
      "Run: 1130 Loss: 0.11642790457225234\n",
      "Run: 1140 Loss: 0.11631030842701093\n",
      "Run: 1150 Loss: 0.11619389192927435\n",
      "Run: 1160 Loss: 0.11607864324559161\n",
      "Run: 1170 Loss: 0.1159645506612145\n",
      "Run: 1180 Loss: 0.11585160257891383\n",
      "Run: 1190 Loss: 0.11573978751779591\n",
      "Run: 1200 Loss: 0.11562909411213122\n",
      "Run: 1210 Loss: 0.11551951111020994\n",
      "Run: 1220 Loss: 0.11541102737318572\n",
      "Run: 1230 Loss: 0.11530363187395654\n",
      "Run: 1240 Loss: 0.11519731369603237\n",
      "Run: 1250 Loss: 0.1150920620324311\n",
      "Run: 1260 Loss: 0.11498786618457801\n",
      "Run: 1270 Loss: 0.11488471556122601\n",
      "Run: 1280 Loss: 0.11478259967736129\n",
      "Run: 1290 Loss: 0.11468150815315949\n",
      "Run: 1300 Loss: 0.11458143071291396\n",
      "Run: 1310 Loss: 0.114482357183999\n",
      "Run: 1320 Loss: 0.11438427749583394\n",
      "Run: 1330 Loss: 0.11428718167885672\n",
      "Run: 1340 Loss: 0.11419105986352013\n",
      "Run: 1350 Loss: 0.114095902279276\n",
      "Run: 1360 Loss: 0.11400169925358815\n",
      "Run: 1370 Loss: 0.11390844121095046\n",
      "Run: 1380 Loss: 0.11381611867191589\n",
      "Run: 1390 Loss: 0.11372472225211938\n",
      "Run: 1400 Loss: 0.11363424266134341\n",
      "Run: 1410 Loss: 0.11354467070255765\n",
      "Run: 1420 Loss: 0.11345599727099408\n",
      "Run: 1430 Loss: 0.11336821335321487\n",
      "Run: 1440 Loss: 0.11328131002620226\n",
      "Run: 1450 Loss: 0.1131952784564435\n",
      "Run: 1460 Loss: 0.11311010989904186\n",
      "Run: 1470 Loss: 0.11302579569682525\n",
      "Run: 1480 Loss: 0.112942327279458\n",
      "Run: 1490 Loss: 0.11285969616258265\n",
      "Run: 1500 Loss: 0.11277789394694929\n",
      "Run: 1510 Loss: 0.1126969123175616\n",
      "Run: 1520 Loss: 0.11261674304283857\n",
      "Run: 1530 Loss: 0.11253737797377018\n",
      "Run: 1540 Loss: 0.11245880904309066\n",
      "Run: 1550 Loss: 0.11238102826446002\n",
      "Run: 1560 Loss: 0.11230402773165678\n",
      "Run: 1570 Loss: 0.11222779961776082\n",
      "Run: 1580 Loss: 0.11215233617437488\n",
      "Run: 1590 Loss: 0.11207762973082544\n",
      "Run: 1600 Loss: 0.11200367269338851\n",
      "Run: 1610 Loss: 0.11193045754450427\n",
      "Run: 1620 Loss: 0.111857976842041\n",
      "Run: 1630 Loss: 0.11178622321851002\n",
      "Run: 1640 Loss: 0.11171518938033227\n",
      "Run: 1650 Loss: 0.11164486810709331\n",
      "Run: 1660 Loss: 0.11157525225080427\n",
      "Run: 1670 Loss: 0.11150633473519057\n",
      "Run: 1680 Loss: 0.11143810855495109\n",
      "Run: 1690 Loss: 0.11137056677506403\n",
      "Run: 1700 Loss: 0.11130370253007492\n",
      "Run: 1710 Loss: 0.11123750902339384\n",
      "Run: 1720 Loss: 0.11117197952661723\n",
      "Run: 1730 Loss: 0.11110710737882791\n",
      "Run: 1740 Loss: 0.1110428859859379\n",
      "Run: 1750 Loss: 0.11097930881999357\n",
      "Run: 1760 Loss: 0.11091636941853758\n",
      "Run: 1770 Loss: 0.11085406138393082\n",
      "Run: 1780 Loss: 0.11079237838271527\n",
      "Run: 1790 Loss: 0.11073131414496858\n",
      "Run: 1800 Loss: 0.11067086246365487\n",
      "Run: 1810 Loss: 0.11061101719401555\n",
      "Run: 1820 Loss: 0.11055177225292157\n",
      "Run: 1830 Loss: 0.11049312161826984\n",
      "Run: 1840 Loss: 0.11043505932837082\n",
      "Run: 1850 Loss: 0.11037757948133275\n",
      "Run: 1860 Loss: 0.11032067623447209\n",
      "Run: 1870 Loss: 0.11026434380371233\n",
      "Run: 1880 Loss: 0.11020857646300111\n",
      "Run: 1890 Loss: 0.11015336854372193\n",
      "Run: 1900 Loss: 0.11009871443413158\n",
      "Run: 1910 Loss: 0.11004460857876762\n",
      "Run: 1920 Loss: 0.10999104547790875\n",
      "Run: 1930 Loss: 0.10993801968699035\n",
      "Run: 1940 Loss: 0.1098855258160765\n",
      "Run: 1950 Loss: 0.1098335585292929\n",
      "Run: 1960 Loss: 0.10978211254429307\n",
      "Run: 1970 Loss: 0.10973118263171507\n",
      "Run: 1980 Loss: 0.10968076361466282\n",
      "Run: 1990 Loss: 0.10963085036816456\n",
      "Run: 2000 Loss: 0.10958143781866428\n",
      "Run: 2010 Loss: 0.10953252094349383\n",
      "Run: 2020 Loss: 0.10948409477037513\n",
      "Run: 2030 Loss: 0.10943615437690633\n",
      "Run: 2040 Loss: 0.10938869489006545\n",
      "Run: 2050 Loss: 0.10934171148570833\n",
      "Run: 2060 Loss: 0.10929519938809179\n",
      "Run: 2070 Loss: 0.10924915386937388\n",
      "Run: 2080 Loss: 0.10920357024913821\n",
      "Run: 2090 Loss: 0.10915844389392446\n",
      "Run: 2100 Loss: 0.1091137702167473\n",
      "Run: 2110 Loss: 0.10906954467664115\n",
      "Run: 2120 Loss: 0.10902576277818406\n",
      "Run: 2130 Loss: 0.10898242007105492\n",
      "Run: 2140 Loss: 0.1089395121495778\n",
      "Run: 2150 Loss: 0.10889703465226122\n",
      "Run: 2160 Loss: 0.10885498326137634\n",
      "Run: 2170 Loss: 0.10881335370250152\n",
      "Run: 2180 Loss: 0.10877214174409347\n",
      "Run: 2190 Loss: 0.10873134319705734\n",
      "Run: 2200 Loss: 0.10869095391432462\n",
      "Run: 2210 Loss: 0.10865096979042153\n",
      "Run: 2220 Loss: 0.10861138676105815\n",
      "Run: 2230 Loss: 0.10857220080271875\n",
      "Run: 2240 Loss: 0.10853340793224797\n",
      "Run: 2250 Loss: 0.10849500420644455\n",
      "Run: 2260 Loss: 0.10845698572166369\n",
      "Run: 2270 Loss: 0.10841934861342135\n",
      "Run: 2280 Loss: 0.10838208905599474\n",
      "Run: 2290 Loss: 0.10834520326204375\n",
      "Run: 2300 Loss: 0.10830868748221884\n",
      "Run: 2310 Loss: 0.10827253800478058\n",
      "Run: 2320 Loss: 0.10823675115521987\n",
      "Run: 2330 Loss: 0.10820132329589527\n",
      "Run: 2340 Loss: 0.10816625082565039\n",
      "Run: 2350 Loss: 0.10813153017945279\n",
      "Run: 2360 Loss: 0.10809715782803678\n",
      "Run: 2370 Loss: 0.1080631302775391\n",
      "Run: 2380 Loss: 0.10802944406913705\n",
      "Run: 2390 Loss: 0.1079960957787133\n",
      "Run: 2400 Loss: 0.10796308201649914\n",
      "Run: 2410 Loss: 0.10793039942671966\n",
      "Run: 2420 Loss: 0.10789804468727601\n",
      "Run: 2430 Loss: 0.10786601450938614\n",
      "Run: 2440 Loss: 0.10783430563726168\n",
      "Run: 2450 Loss: 0.10780291484777509\n",
      "Run: 2460 Loss: 0.10777183895012296\n",
      "Run: 2470 Loss: 0.10774107478552603\n",
      "Run: 2480 Loss: 0.1077106192268748\n",
      "Run: 2490 Loss: 0.10768046917844223\n",
      "Run: 2500 Loss: 0.10765062157554453\n",
      "Run: 2510 Loss: 0.10762107338425204\n",
      "Run: 2520 Loss: 0.10759182160105925\n",
      "Run: 2530 Loss: 0.10756286325259592\n",
      "Run: 2540 Loss: 0.10753419539531561\n",
      "Run: 2550 Loss: 0.10750581511520334\n",
      "Run: 2560 Loss: 0.10747771952747293\n",
      "Run: 2570 Loss: 0.10744990577627529\n",
      "Run: 2580 Loss: 0.1074223710344119\n",
      "Run: 2590 Loss: 0.10739511250304333\n",
      "Run: 2600 Loss: 0.10736812741140944\n",
      "Run: 2610 Loss: 0.1073414130165373\n",
      "Run: 2620 Loss: 0.10731496660297765\n",
      "Run: 2630 Loss: 0.10728878548251525\n",
      "Run: 2640 Loss: 0.10726286699390658\n",
      "Run: 2650 Loss: 0.10723720850259778\n",
      "Run: 2660 Loss: 0.10721180740046991\n",
      "Run: 2670 Loss: 0.10718666110556094\n",
      "Run: 2680 Loss: 0.10716176706180762\n",
      "Run: 2690 Loss: 0.10713712273879933\n",
      "Run: 2700 Loss: 0.10711272563149578\n",
      "Run: 2710 Loss: 0.10708857325999539\n",
      "Run: 2720 Loss: 0.10706466316926211\n",
      "Run: 2730 Loss: 0.107040992928901\n",
      "Run: 2740 Loss: 0.10701756013288664\n",
      "Run: 2750 Loss: 0.10699436239933371\n",
      "Run: 2760 Loss: 0.10697139737024972\n",
      "Run: 2770 Loss: 0.10694866271129508\n",
      "Run: 2780 Loss: 0.10692615611154786\n",
      "Run: 2790 Loss: 0.10690387528326685\n",
      "Run: 2800 Loss: 0.1068818179616644\n",
      "Run: 2810 Loss: 0.10685998190466067\n",
      "Run: 2820 Loss: 0.10683836489268027\n",
      "Run: 2830 Loss: 0.10681696472840486\n",
      "Run: 2840 Loss: 0.10679577923656136\n",
      "Run: 2850 Loss: 0.10677480626369569\n",
      "Run: 2860 Loss: 0.10675404367795695\n",
      "Run: 2870 Loss: 0.10673348936887614\n",
      "Run: 2880 Loss: 0.10671314124716266\n",
      "Run: 2890 Loss: 0.10669299724447906\n",
      "Run: 2900 Loss: 0.10667305531323625\n",
      "Run: 2910 Loss: 0.1066533134263843\n",
      "Run: 2920 Loss: 0.10663376957721017\n",
      "Run: 2930 Loss: 0.10661442177913122\n",
      "Run: 2940 Loss: 0.10659526806548995\n",
      "Run: 2950 Loss: 0.1065763064893564\n",
      "Run: 2960 Loss: 0.10655753512333777\n",
      "Run: 2970 Loss: 0.10653895205936662\n",
      "Run: 2980 Loss: 0.10652055540852114\n",
      "Run: 2990 Loss: 0.10650234330082721\n",
      "Run: 3000 Loss: 0.1064843138850695\n",
      "Run: 3010 Loss: 0.10646646532860052\n",
      "Run: 3020 Loss: 0.10644879581715931\n",
      "Run: 3030 Loss: 0.10643130355468272\n",
      "Run: 3040 Loss: 0.10641398676312809\n",
      "Run: 3050 Loss: 0.10639684368228446\n",
      "Run: 3060 Loss: 0.10637987256959701\n",
      "Run: 3070 Loss: 0.10636307169999736\n",
      "Run: 3080 Loss: 0.10634643936571517\n",
      "Run: 3090 Loss: 0.1063299738761179\n",
      "Run: 3100 Loss: 0.10631367355752731\n",
      "Run: 3110 Loss: 0.10629753675305685\n",
      "Run: 3120 Loss: 0.10628156182243782\n",
      "Run: 3130 Loss: 0.10626574714186104\n",
      "Run: 3140 Loss: 0.10625009110380036\n",
      "Run: 3150 Loss: 0.10623459211685762\n",
      "Run: 3160 Loss: 0.10621924860560246\n",
      "Run: 3170 Loss: 0.10620405901039962\n",
      "Run: 3180 Loss: 0.10618902178726856\n",
      "Run: 3190 Loss: 0.10617413540771156\n",
      "Run: 3200 Loss: 0.10615939835856121\n",
      "Run: 3210 Loss: 0.10614480914183826\n",
      "Run: 3220 Loss: 0.10613036627457927\n",
      "Run: 3230 Loss: 0.10611606828870439\n",
      "Run: 3240 Loss: 0.10610191373085956\n",
      "Run: 3250 Loss: 0.10608790116226897\n",
      "Run: 3260 Loss: 0.10607402915858696\n",
      "Run: 3270 Loss: 0.10606029630975954\n",
      "Run: 3280 Loss: 0.10604670121987707\n",
      "Run: 3290 Loss: 0.10603324250703179\n",
      "Run: 3300 Loss: 0.10601991880318022\n",
      "Run: 3310 Loss: 0.10600672875399475\n",
      "Run: 3320 Loss: 0.10599367101874695\n",
      "Run: 3330 Loss: 0.10598074427014437\n",
      "Run: 3340 Loss: 0.10596794719421725\n",
      "Run: 3350 Loss: 0.10595527849017339\n",
      "Run: 3360 Loss: 0.10594273687026996\n",
      "Run: 3370 Loss: 0.10593032105968593\n",
      "Run: 3380 Loss: 0.10591802979637743\n",
      "Run: 3390 Loss: 0.10590586183097385\n",
      "Run: 3400 Loss: 0.10589381592662901\n",
      "Run: 3410 Loss: 0.10588189085890679\n",
      "Run: 3420 Loss: 0.10587008541565163\n",
      "Run: 3430 Loss: 0.10585839839687239\n",
      "Run: 3440 Loss: 0.10584682861461092\n",
      "Run: 3450 Loss: 0.1058353748928247\n",
      "Run: 3460 Loss: 0.10582403606727518\n",
      "Run: 3470 Loss: 0.10581281098539544\n",
      "Run: 3480 Loss: 0.1058016985061869\n",
      "Run: 3490 Loss: 0.10579069750008989\n",
      "Run: 3500 Loss: 0.10577980684887954\n",
      "Run: 3510 Loss: 0.10576902544555018\n",
      "Run: 3520 Loss: 0.10575835219419605\n",
      "Run: 3530 Loss: 0.10574778600990882\n",
      "Run: 3540 Loss: 0.10573732581866192\n",
      "Run: 3550 Loss: 0.1057269705572026\n",
      "Run: 3560 Loss: 0.10571671917294181\n",
      "Run: 3570 Loss: 0.10570657062385519\n",
      "Run: 3580 Loss: 0.10569652387836628\n",
      "Run: 3590 Loss: 0.10568657791524647\n",
      "Run: 3600 Loss: 0.10567673172351387\n",
      "Run: 3610 Loss: 0.10566698430232747\n",
      "Run: 3620 Loss: 0.10565733466088825\n",
      "Run: 3630 Loss: 0.10564778181832783\n",
      "Run: 3640 Loss: 0.10563832480362866\n",
      "Run: 3650 Loss: 0.10562896265550657\n",
      "Run: 3660 Loss: 0.10561969442232284\n",
      "Run: 3670 Loss: 0.10561051916198295\n",
      "Run: 3680 Loss: 0.10560143594184475\n",
      "Run: 3690 Loss: 0.1055924438386239\n",
      "Run: 3700 Loss: 0.1055835419382905\n",
      "Run: 3710 Loss: 0.10557472933599182\n",
      "Run: 3720 Loss: 0.10556600513594455\n",
      "Run: 3730 Loss: 0.10555736845136031\n",
      "Run: 3740 Loss: 0.10554881840433833\n",
      "Run: 3750 Loss: 0.10554035412578823\n",
      "Run: 3760 Loss: 0.10553197475533649\n",
      "Run: 3770 Loss: 0.10552367944123998\n",
      "Run: 3780 Loss: 0.10551546734030072\n",
      "Run: 3790 Loss: 0.10550733761777895\n",
      "Run: 3800 Loss: 0.10549928944731027\n",
      "Run: 3810 Loss: 0.10549132201081672\n",
      "Run: 3820 Loss: 0.10548343449842507\n",
      "Run: 3830 Loss: 0.10547562610839092\n",
      "Run: 3840 Loss: 0.10546789604701469\n",
      "Run: 3850 Loss: 0.1054602435285482\n",
      "Run: 3860 Loss: 0.10545266777513446\n",
      "Run: 3870 Loss: 0.10544516801671847\n",
      "Run: 3880 Loss: 0.10543774349096763\n",
      "Run: 3890 Loss: 0.10543039344319406\n",
      "Run: 3900 Loss: 0.10542311712628563\n",
      "Run: 3910 Loss: 0.10541591380062132\n",
      "Run: 3920 Loss: 0.10540878273400449\n",
      "Run: 3930 Loss: 0.10540172320157518\n",
      "Run: 3940 Loss: 0.10539473448575264\n",
      "Run: 3950 Loss: 0.1053878158761502\n",
      "Run: 3960 Loss: 0.10538096666950547\n",
      "Run: 3970 Loss: 0.10537418616961665\n",
      "Run: 3980 Loss: 0.1053674736872609\n",
      "Run: 3990 Loss: 0.10536082854013398\n",
      "Run: 4000 Loss: 0.10535425005276844\n",
      "Run: 4010 Loss: 0.10534773755647892\n",
      "Run: 4020 Loss: 0.10534129038928818\n",
      "Run: 4030 Loss: 0.1053349078958531\n",
      "Run: 4040 Loss: 0.1053285894274127\n",
      "Run: 4050 Loss: 0.1053223343417124\n",
      "Run: 4060 Loss: 0.10531614200293014\n",
      "Run: 4070 Loss: 0.10531001178163744\n",
      "Run: 4080 Loss: 0.10530394305470828\n",
      "Run: 4090 Loss: 0.10529793520527307\n",
      "Run: 4100 Loss: 0.10529198762264838\n",
      "Run: 4110 Loss: 0.10528609970227648\n",
      "Run: 4120 Loss: 0.1052802708456667\n",
      "Run: 4130 Loss: 0.10527450046032635\n",
      "Run: 4140 Loss: 0.10526878795971428\n",
      "Run: 4150 Loss: 0.10526313276316464\n",
      "Run: 4160 Loss: 0.10525753429584303\n",
      "Run: 4170 Loss: 0.10525199198867936\n",
      "Run: 4180 Loss: 0.10524650527831202\n",
      "Run: 4190 Loss: 0.10524107360702878\n",
      "Run: 4200 Loss: 0.10523569642271285\n",
      "Run: 4210 Loss: 0.10523037317878961\n",
      "Run: 4220 Loss: 0.1052251033341598\n",
      "Run: 4230 Loss: 0.105219886353162\n",
      "Run: 4240 Loss: 0.10521472170549943\n",
      "Run: 4250 Loss: 0.10520960886620064\n",
      "Run: 4260 Loss: 0.10520454731555684\n",
      "Run: 4270 Loss: 0.10519953653907249\n",
      "Run: 4280 Loss: 0.10519457602741605\n",
      "Run: 4290 Loss: 0.10518966527636459\n",
      "Run: 4300 Loss: 0.10518480378675041\n",
      "Run: 4310 Loss: 0.1051799910644154\n",
      "Run: 4320 Loss: 0.10517522662015921\n",
      "Run: 4330 Loss: 0.10517050996968598\n",
      "Run: 4340 Loss: 0.10516584063356282\n",
      "Run: 4350 Loss: 0.10516121813715915\n",
      "Run: 4360 Loss: 0.10515664201061352\n",
      "Run: 4370 Loss: 0.10515211178877086\n",
      "Run: 4380 Loss: 0.10514762701114655\n",
      "Run: 4390 Loss: 0.10514318722187438\n",
      "Run: 4400 Loss: 0.10513879196966008\n",
      "Run: 4410 Loss: 0.10513444080773522\n",
      "Run: 4420 Loss: 0.1051301332938212\n",
      "Run: 4430 Loss: 0.1051258689900603\n",
      "Run: 4440 Loss: 0.10512164746300477\n",
      "Run: 4450 Loss: 0.10511746828354333\n",
      "Run: 4460 Loss: 0.10511333102687219\n",
      "Run: 4470 Loss: 0.10510923527245024\n",
      "Run: 4480 Loss: 0.10510518060395449\n",
      "Run: 4490 Loss: 0.10510116660923743\n",
      "Run: 4500 Loss: 0.10509719288028498\n",
      "Run: 4510 Loss: 0.10509325901317908\n",
      "Run: 4520 Loss: 0.1050893646080517\n",
      "Run: 4530 Loss: 0.10508550926904475\n",
      "Run: 4540 Loss: 0.1050816926042741\n",
      "Run: 4550 Loss: 0.10507791422578479\n",
      "Run: 4560 Loss: 0.10507417374951306\n",
      "Run: 4570 Loss: 0.10507047079525142\n",
      "Run: 4580 Loss: 0.10506680498659997\n",
      "Run: 4590 Loss: 0.1050631759509388\n",
      "Run: 4600 Loss: 0.10505958331938903\n",
      "Run: 4610 Loss: 0.10505602672676359\n",
      "Run: 4620 Loss: 0.10505250581154664\n",
      "Run: 4630 Loss: 0.1050490202158449\n",
      "Run: 4640 Loss: 0.10504556958535663\n",
      "Run: 4650 Loss: 0.10504215356933057\n",
      "Run: 4660 Loss: 0.10503877182054222\n",
      "Run: 4670 Loss: 0.10503542399524143\n",
      "Run: 4680 Loss: 0.10503210975313372\n",
      "Run: 4690 Loss: 0.1050288287573313\n",
      "Run: 4700 Loss: 0.10502558067432825\n",
      "Run: 4710 Loss: 0.1050223651739666\n",
      "Run: 4720 Loss: 0.1050191819293986\n",
      "Run: 4730 Loss: 0.10501603061705526\n",
      "Run: 4740 Loss: 0.1050129109166133\n",
      "Run: 4750 Loss: 0.10500982251096365\n",
      "Run: 4760 Loss: 0.1050067650861752\n",
      "Run: 4770 Loss: 0.10500373833147145\n",
      "Run: 4780 Loss: 0.10500074193918713\n",
      "Run: 4790 Loss: 0.10499777560474707\n",
      "Run: 4800 Loss: 0.10499483902663209\n",
      "Run: 4810 Loss: 0.10499193190634612\n",
      "Run: 4820 Loss: 0.10498905394838307\n",
      "Run: 4830 Loss: 0.10498620486021343\n",
      "Run: 4840 Loss: 0.10498338435222744\n",
      "Run: 4850 Loss: 0.10498059213773142\n",
      "Run: 4860 Loss: 0.10497782793290282\n",
      "Run: 4870 Loss: 0.10497509145676576\n",
      "Run: 4880 Loss: 0.10497238243116509\n",
      "Run: 4890 Loss: 0.10496970058073389\n",
      "Run: 4900 Loss: 0.10496704563287147\n",
      "Run: 4910 Loss: 0.1049644173177069\n",
      "Run: 4920 Loss: 0.1049618153680747\n",
      "Run: 4930 Loss: 0.10495923951950163\n",
      "Run: 4940 Loss: 0.10495668951015219\n",
      "Run: 4950 Loss: 0.10495416508082663\n",
      "Run: 4960 Loss: 0.10495166597492168\n",
      "Run: 4970 Loss: 0.10494919193841176\n",
      "Run: 4980 Loss: 0.10494674271981597\n",
      "Run: 4990 Loss: 0.10494431807017475\n",
      "Run: 5000 Loss: 0.10494191774303226\n",
      "Run: 5010 Loss: 0.10493954149440012\n",
      "Run: 5020 Loss: 0.10493718908273578\n",
      "Run: 5030 Loss: 0.10493486026892622\n",
      "Run: 5040 Loss: 0.10493255481624945\n",
      "Run: 5050 Loss: 0.10493027249036667\n",
      "Run: 5060 Loss: 0.10492801305927948\n",
      "Run: 5070 Loss: 0.10492577629332724\n",
      "Run: 5080 Loss: 0.10492356196514328\n",
      "Run: 5090 Loss: 0.10492136984965121\n",
      "Run: 5100 Loss: 0.10491919972402507\n",
      "Run: 5110 Loss: 0.10491705136767923\n",
      "Run: 5120 Loss: 0.10491492456223644\n",
      "Run: 5130 Loss: 0.10491281909151248\n",
      "Run: 5140 Loss: 0.10491073474149146\n",
      "Run: 5150 Loss: 0.104908671300306\n",
      "Run: 5160 Loss: 0.1049066285582079\n",
      "Run: 5170 Loss: 0.10490460630756401\n",
      "Run: 5180 Loss: 0.1049026043428118\n",
      "Run: 5190 Loss: 0.10490062246046038\n",
      "Run: 5200 Loss: 0.10489866045905347\n",
      "Run: 5210 Loss: 0.10489671813916158\n",
      "Run: 5220 Loss: 0.10489479530334657\n",
      "Run: 5230 Loss: 0.10489289175616423\n",
      "Run: 5240 Loss: 0.10489100730411839\n",
      "Run: 5250 Loss: 0.10488914175566356\n",
      "Run: 5260 Loss: 0.10488729492116904\n",
      "Run: 5270 Loss: 0.1048854666129051\n",
      "Run: 5280 Loss: 0.10488365664503578\n",
      "Run: 5290 Loss: 0.10488186483357537\n",
      "Run: 5300 Loss: 0.10488009099639571\n",
      "Run: 5310 Loss: 0.10487833495318968\n",
      "Run: 5320 Loss: 0.10487659652545608\n",
      "Run: 5330 Loss: 0.10487487553649341\n",
      "Run: 5340 Loss: 0.10487317181136338\n",
      "Run: 5350 Loss: 0.10487148517688898\n",
      "Run: 5360 Loss: 0.10486981546162456\n",
      "Run: 5370 Loss: 0.10486816249585282\n",
      "Run: 5380 Loss: 0.10486652611155102\n",
      "Run: 5390 Loss: 0.10486490614238453\n",
      "Run: 5400 Loss: 0.10486330242368602\n",
      "Run: 5410 Loss: 0.10486171479244441\n",
      "Run: 5420 Loss: 0.10486014308727681\n",
      "Run: 5430 Loss: 0.1048585871484289\n",
      "Run: 5440 Loss: 0.10485704681773997\n",
      "Run: 5450 Loss: 0.10485552193863987\n",
      "Run: 5460 Loss: 0.10485401235612665\n",
      "Run: 5470 Loss: 0.10485251791675693\n",
      "Run: 5480 Loss: 0.10485103846862462\n",
      "Run: 5490 Loss: 0.10484957386134709\n",
      "Run: 5500 Loss: 0.1048481239460504\n",
      "Run: 5510 Loss: 0.10484668857535334\n",
      "Run: 5520 Loss: 0.1048452676033559\n",
      "Run: 5530 Loss: 0.10484386088561955\n",
      "Run: 5540 Loss: 0.10484246827915361\n",
      "Run: 5550 Loss: 0.10484108964240181\n",
      "Run: 5560 Loss: 0.1048397248352324\n",
      "Run: 5570 Loss: 0.10483837371891458\n",
      "Run: 5580 Loss: 0.1048370361561113\n",
      "Run: 5590 Loss: 0.10483571201086057\n",
      "Run: 5600 Loss: 0.10483440114856768\n",
      "Run: 5610 Loss: 0.10483310343598667\n",
      "Run: 5620 Loss: 0.10483181874121011\n",
      "Run: 5630 Loss: 0.10483054693364868\n",
      "Run: 5640 Loss: 0.10482928788402843\n",
      "Run: 5650 Loss: 0.104828041464368\n",
      "Run: 5660 Loss: 0.104826807547975\n",
      "Run: 5670 Loss: 0.10482558600941977\n",
      "Run: 5680 Loss: 0.10482437672454303\n",
      "Run: 5690 Loss: 0.10482317957041863\n",
      "Run: 5700 Loss: 0.10482199442536076\n",
      "Run: 5710 Loss: 0.10482082116889994\n",
      "Run: 5720 Loss: 0.1048196596817809\n",
      "Run: 5730 Loss: 0.10481850984594163\n",
      "Run: 5740 Loss: 0.10481737154449833\n",
      "Run: 5750 Loss: 0.10481624466175316\n",
      "Run: 5760 Loss: 0.10481512908315635\n",
      "Run: 5770 Loss: 0.10481402469531328\n",
      "Run: 5780 Loss: 0.10481293138596472\n",
      "Run: 5790 Loss: 0.10481184904398057\n",
      "Run: 5800 Loss: 0.10481077755934108\n",
      "Run: 5810 Loss: 0.10480971682313461\n",
      "Run: 5820 Loss: 0.10480866672754045\n",
      "Run: 5830 Loss: 0.1048076271658133\n",
      "Run: 5840 Loss: 0.10480659803229166\n",
      "Run: 5850 Loss: 0.10480557922236335\n",
      "Run: 5860 Loss: 0.10480457063246916\n",
      "Run: 5870 Loss: 0.10480357216008628\n",
      "Run: 5880 Loss: 0.10480258370372611\n",
      "Run: 5890 Loss: 0.10480160516291243\n",
      "Run: 5900 Loss: 0.1048006364381774\n",
      "Run: 5910 Loss: 0.1047996774310565\n",
      "Run: 5920 Loss: 0.10479872804406601\n",
      "Run: 5930 Loss: 0.10479778818070468\n",
      "Run: 5940 Loss: 0.10479685774543644\n",
      "Run: 5950 Loss: 0.10479593664368751\n",
      "Run: 5960 Loss: 0.10479502478182566\n",
      "Run: 5970 Loss: 0.10479412206716371\n",
      "Run: 5980 Loss: 0.10479322840794551\n",
      "Run: 5990 Loss: 0.10479234371333258\n",
      "Run: 6000 Loss: 0.1047914678933941\n",
      "Run: 6010 Loss: 0.10479060085910949\n",
      "Run: 6020 Loss: 0.10478974252234217\n",
      "Run: 6030 Loss: 0.10478889279585078\n",
      "Run: 6040 Loss: 0.10478805159325638\n",
      "Run: 6050 Loss: 0.10478721882905635\n",
      "Run: 6060 Loss: 0.10478639441860137\n",
      "Run: 6070 Loss: 0.1047855782780903\n",
      "Run: 6080 Loss: 0.10478477032456884\n",
      "Run: 6090 Loss: 0.10478397047590665\n",
      "Run: 6100 Loss: 0.10478317865080303\n",
      "Run: 6110 Loss: 0.10478239476876923\n",
      "Run: 6120 Loss: 0.10478161875012719\n",
      "Run: 6130 Loss: 0.1047808505159959\n",
      "Run: 6140 Loss: 0.10478008998828707\n",
      "Run: 6150 Loss: 0.10477933708969255\n",
      "Run: 6160 Loss: 0.10477859174368288\n",
      "Run: 6170 Loss: 0.10477785387449781\n",
      "Run: 6180 Loss: 0.10477712340713403\n",
      "Run: 6190 Loss: 0.10477640026733885\n",
      "Run: 6200 Loss: 0.10477568438160899\n",
      "Run: 6210 Loss: 0.10477497567717466\n",
      "Run: 6220 Loss: 0.1047742740820002\n",
      "Run: 6230 Loss: 0.1047735795247686\n",
      "Run: 6240 Loss: 0.10477289193488033\n",
      "Run: 6250 Loss: 0.10477221124244367\n",
      "Run: 6260 Loss: 0.10477153737826786\n",
      "Run: 6270 Loss: 0.10477087027385461\n",
      "Run: 6280 Loss: 0.10477020986139836\n",
      "Run: 6290 Loss: 0.10476955607376473\n",
      "Run: 6300 Loss: 0.1047689088445025\n",
      "Run: 6310 Loss: 0.10476826810781979\n",
      "Run: 6320 Loss: 0.10476763379858567\n",
      "Run: 6330 Loss: 0.1047670058523295\n",
      "Run: 6340 Loss: 0.10476638420521654\n",
      "Run: 6350 Loss: 0.10476576879406117\n",
      "Run: 6360 Loss: 0.10476515955630879\n",
      "Run: 6370 Loss: 0.1047645564300274\n",
      "Run: 6380 Loss: 0.1047639593539166\n",
      "Run: 6390 Loss: 0.10476336826728139\n",
      "Run: 6400 Loss: 0.10476278311003795\n",
      "Run: 6410 Loss: 0.10476220382271213\n",
      "Run: 6420 Loss: 0.10476163034641535\n",
      "Run: 6430 Loss: 0.1047610626228578\n",
      "Run: 6440 Loss: 0.10476050059433135\n",
      "Run: 6450 Loss: 0.104759944203706\n",
      "Run: 6460 Loss: 0.10475939339442865\n",
      "Run: 6470 Loss: 0.10475884811050798\n",
      "Run: 6480 Loss: 0.10475830829651796\n",
      "Run: 6490 Loss: 0.1047577738975888\n",
      "Run: 6500 Loss: 0.1047572448593995\n",
      "Run: 6510 Loss: 0.10475672112817414\n",
      "Run: 6520 Loss: 0.10475620265067997\n",
      "Run: 6530 Loss: 0.10475568937421065\n",
      "Run: 6540 Loss: 0.10475518124659587\n",
      "Run: 6550 Loss: 0.10475467821618165\n",
      "Run: 6560 Loss: 0.10475418023184035\n",
      "Run: 6570 Loss: 0.10475368724295385\n",
      "Run: 6580 Loss: 0.10475319919940634\n",
      "Run: 6590 Loss: 0.10475271605159292\n",
      "Run: 6600 Loss: 0.10475223775040367\n",
      "Run: 6610 Loss: 0.10475176424721613\n",
      "Run: 6620 Loss: 0.1047512954939033\n",
      "Run: 6630 Loss: 0.10475083144281819\n",
      "Run: 6640 Loss: 0.10475037204678761\n",
      "Run: 6650 Loss: 0.10474991725911684\n",
      "Run: 6660 Loss: 0.10474946703357833\n",
      "Run: 6670 Loss: 0.10474902132440787\n",
      "Run: 6680 Loss: 0.10474858008630068\n",
      "Run: 6690 Loss: 0.10474814327440433\n",
      "Run: 6700 Loss: 0.10474771084432051\n",
      "Run: 6710 Loss: 0.10474728275208971\n",
      "Run: 6720 Loss: 0.10474685895420036\n",
      "Run: 6730 Loss: 0.1047464394075745\n",
      "Run: 6740 Loss: 0.10474602406956492\n",
      "Run: 6750 Loss: 0.10474561289795564\n",
      "Run: 6760 Loss: 0.10474520585094971\n",
      "Run: 6770 Loss: 0.10474480288717292\n",
      "Run: 6780 Loss: 0.10474440396566473\n",
      "Run: 6790 Loss: 0.10474400904587508\n",
      "Run: 6800 Loss: 0.10474361808766074\n",
      "Run: 6810 Loss: 0.10474323105128697\n",
      "Run: 6820 Loss: 0.1047428478974066\n",
      "Run: 6830 Loss: 0.10474246858707384\n",
      "Run: 6840 Loss: 0.10474209308173535\n",
      "Run: 6850 Loss: 0.1047417213432202\n",
      "Run: 6860 Loss: 0.10474135333374236\n",
      "Run: 6870 Loss: 0.10474098901589454\n",
      "Run: 6880 Loss: 0.10474062835264474\n",
      "Run: 6890 Loss: 0.10474027130733266\n",
      "Run: 6900 Loss: 0.1047399178436653\n",
      "Run: 6910 Loss: 0.1047395679257136\n",
      "Run: 6920 Loss: 0.1047392215179092\n",
      "Run: 6930 Loss: 0.10473887858504115\n",
      "Run: 6940 Loss: 0.10473853909225062\n",
      "Run: 6950 Loss: 0.1047382030050303\n",
      "Run: 6960 Loss: 0.10473787028921835\n",
      "Run: 6970 Loss: 0.10473754091098925\n",
      "Run: 6980 Loss: 0.1047372148368719\n",
      "Run: 6990 Loss: 0.10473689203371316\n",
      "Run: 7000 Loss: 0.10473657246870499\n",
      "Run: 7010 Loss: 0.10473625610936382\n",
      "Run: 7020 Loss: 0.10473594292353103\n",
      "Run: 7030 Loss: 0.10473563287937449\n",
      "Run: 7040 Loss: 0.10473532594537832\n",
      "Run: 7050 Loss: 0.10473502209034247\n",
      "Run: 7060 Loss: 0.10473472128338232\n",
      "Run: 7070 Loss: 0.10473442349391882\n",
      "Run: 7080 Loss: 0.1047341286916859\n",
      "Run: 7090 Loss: 0.10473383684671402\n",
      "Run: 7100 Loss: 0.10473354792934043\n",
      "Run: 7110 Loss: 0.104733261910198\n",
      "Run: 7120 Loss: 0.10473297876021044\n",
      "Run: 7130 Loss: 0.10473269845060013\n",
      "Run: 7140 Loss: 0.1047324209528714\n",
      "Run: 7150 Loss: 0.10473214623881721\n",
      "Run: 7160 Loss: 0.1047318742805158\n",
      "Run: 7170 Loss: 0.10473160505032031\n",
      "Run: 7180 Loss: 0.10473133852086652\n",
      "Run: 7190 Loss: 0.10473107466506319\n",
      "Run: 7200 Loss: 0.10473081345608683\n",
      "Run: 7210 Loss: 0.10473055486738826\n",
      "Run: 7220 Loss: 0.10473029887268033\n",
      "Run: 7230 Loss: 0.10473004544594607\n",
      "Run: 7240 Loss: 0.10472979456142083\n",
      "Run: 7250 Loss: 0.10472954619360611\n",
      "Run: 7260 Loss: 0.10472930031725508\n",
      "Run: 7270 Loss: 0.10472905690737443\n",
      "Run: 7280 Loss: 0.10472881593922011\n",
      "Run: 7290 Loss: 0.10472857738830375\n",
      "Run: 7300 Loss: 0.10472834123037217\n",
      "Run: 7310 Loss: 0.10472810744142308\n",
      "Run: 7320 Loss: 0.10472787599769011\n",
      "Run: 7330 Loss: 0.10472764687564967\n",
      "Run: 7340 Loss: 0.10472742005201145\n",
      "Run: 7350 Loss: 0.1047271955037193\n",
      "Run: 7360 Loss: 0.10472697320794838\n",
      "Run: 7370 Loss: 0.10472675314210343\n",
      "Run: 7380 Loss: 0.10472653528381523\n",
      "Run: 7390 Loss: 0.10472631961093978\n",
      "Run: 7400 Loss: 0.10472610610155147\n",
      "Run: 7410 Loss: 0.10472589473395016\n",
      "Run: 7420 Loss: 0.10472568548665116\n",
      "Run: 7430 Loss: 0.10472547833838232\n",
      "Run: 7440 Loss: 0.10472527326808845\n",
      "Run: 7450 Loss: 0.10472507025492786\n",
      "Run: 7460 Loss: 0.10472486927826084\n",
      "Run: 7470 Loss: 0.10472467031766096\n",
      "Run: 7480 Loss: 0.10472447335290357\n",
      "Run: 7490 Loss: 0.10472427836396674\n",
      "Run: 7500 Loss: 0.1047240853310312\n",
      "Run: 7510 Loss: 0.10472389423447562\n",
      "Run: 7520 Loss: 0.10472370505487742\n",
      "Run: 7530 Loss: 0.10472351777300462\n",
      "Run: 7540 Loss: 0.10472333236981876\n",
      "Run: 7550 Loss: 0.10472314882647808\n",
      "Run: 7560 Loss: 0.1047229671243214\n",
      "Run: 7570 Loss: 0.10472278724488407\n",
      "Run: 7580 Loss: 0.1047226091698791\n",
      "Run: 7590 Loss: 0.10472243288120574\n",
      "Run: 7600 Loss: 0.10472225836094533\n",
      "Run: 7610 Loss: 0.10472208559135644\n",
      "Run: 7620 Loss: 0.1047219145548812\n",
      "Run: 7630 Loss: 0.10472174523412947\n",
      "Run: 7640 Loss: 0.10472157761189471\n",
      "Run: 7650 Loss: 0.10472141167113566\n",
      "Run: 7660 Loss: 0.10472124739498533\n",
      "Run: 7670 Loss: 0.10472108476674359\n",
      "Run: 7680 Loss: 0.10472092376988694\n",
      "Run: 7690 Loss: 0.10472076438804001\n",
      "Run: 7700 Loss: 0.10472060660500969\n",
      "Run: 7710 Loss: 0.10472045040475604\n",
      "Run: 7720 Loss: 0.10472029577140017\n",
      "Run: 7730 Loss: 0.10472014268922497\n",
      "Run: 7740 Loss: 0.10471999114267039\n",
      "Run: 7750 Loss: 0.10471984111633115\n",
      "Run: 7760 Loss: 0.10471969259495913\n",
      "Run: 7770 Loss: 0.10471954556345449\n",
      "Run: 7780 Loss: 0.10471940000687467\n",
      "Run: 7790 Loss: 0.10471925591042221\n",
      "Run: 7800 Loss: 0.10471911325945105\n",
      "Run: 7810 Loss: 0.1047189720394618\n",
      "Run: 7820 Loss: 0.10471883223609664\n",
      "Run: 7830 Loss: 0.10471869383515034\n",
      "Run: 7840 Loss: 0.10471855682254926\n",
      "Run: 7850 Loss: 0.10471842118437058\n",
      "Run: 7860 Loss: 0.10471828690682551\n",
      "Run: 7870 Loss: 0.10471815397626344\n",
      "Run: 7880 Loss: 0.10471802237917412\n",
      "Run: 7890 Loss: 0.10471789210218095\n",
      "Run: 7900 Loss: 0.10471776313204216\n",
      "Run: 7910 Loss: 0.10471763545564594\n",
      "Run: 7920 Loss: 0.10471750906001735\n",
      "Run: 7930 Loss: 0.10471738393230429\n",
      "Run: 7940 Loss: 0.10471726005979093\n",
      "Run: 7950 Loss: 0.10471713742988684\n",
      "Run: 7960 Loss: 0.10471701603012541\n",
      "Run: 7970 Loss: 0.10471689584816608\n",
      "Run: 7980 Loss: 0.10471677687179541\n",
      "Run: 7990 Loss: 0.10471665908891566\n",
      "Run: 8000 Loss: 0.10471654248755662\n",
      "Run: 8010 Loss: 0.10471642705586767\n",
      "Run: 8020 Loss: 0.10471631278211255\n",
      "Run: 8030 Loss: 0.1047161996546768\n",
      "Run: 8040 Loss: 0.1047160876620611\n",
      "Run: 8050 Loss: 0.1047159767928849\n",
      "Run: 8060 Loss: 0.10471586703587314\n",
      "Run: 8070 Loss: 0.10471575837987118\n",
      "Run: 8080 Loss: 0.10471565081383469\n",
      "Run: 8090 Loss: 0.10471554432683405\n",
      "Run: 8100 Loss: 0.10471543890803692\n",
      "Run: 8110 Loss: 0.10471533454673529\n",
      "Run: 8120 Loss: 0.10471523123231502\n",
      "Run: 8130 Loss: 0.10471512895428003\n",
      "Run: 8140 Loss: 0.10471502770222904\n",
      "Run: 8150 Loss: 0.1047149274658735\n",
      "Run: 8160 Loss: 0.1047148282350237\n",
      "Run: 8170 Loss: 0.10471472999959282\n",
      "Run: 8180 Loss: 0.1047146327495956\n",
      "Run: 8190 Loss: 0.10471453647514416\n",
      "Run: 8200 Loss: 0.10471444116645755\n",
      "Run: 8210 Loss: 0.10471434681384562\n",
      "Run: 8220 Loss: 0.10471425340771356\n",
      "Run: 8230 Loss: 0.10471416093857486\n",
      "Run: 8240 Loss: 0.10471406939702323\n",
      "Run: 8250 Loss: 0.10471397877375992\n",
      "Run: 8260 Loss: 0.10471388905956552\n",
      "Run: 8270 Loss: 0.10471380024532903\n",
      "Run: 8280 Loss: 0.10471371232201593\n",
      "Run: 8290 Loss: 0.10471362528069239\n",
      "Run: 8300 Loss: 0.10471353911251194\n",
      "Run: 8310 Loss: 0.10471345380871379\n",
      "Run: 8320 Loss: 0.10471336936062561\n",
      "Run: 8330 Loss: 0.1047132857596669\n",
      "Run: 8340 Loss: 0.10471320299733872\n",
      "Run: 8350 Loss: 0.10471312106522782\n",
      "Run: 8360 Loss: 0.10471303995500515\n",
      "Run: 8370 Loss: 0.10471295965842835\n",
      "Run: 8380 Loss: 0.10471288016733139\n",
      "Run: 8390 Loss: 0.10471280147363973\n",
      "Run: 8400 Loss: 0.10471272356935059\n",
      "Run: 8410 Loss: 0.10471264644654839\n",
      "Run: 8420 Loss: 0.10471257009739089\n",
      "Run: 8430 Loss: 0.10471249451411488\n",
      "Run: 8440 Loss: 0.10471241968904459\n",
      "Run: 8450 Loss: 0.1047123456145684\n",
      "Run: 8460 Loss: 0.10471227228315864\n",
      "Run: 8470 Loss: 0.10471219968736274\n",
      "Run: 8480 Loss: 0.10471212781979913\n",
      "Run: 8490 Loss: 0.10471205667316605\n",
      "Run: 8500 Loss: 0.1047119862402271\n",
      "Run: 8510 Loss: 0.10471191651382605\n",
      "Run: 8520 Loss: 0.10471184748687534\n",
      "Run: 8530 Loss: 0.10471177915235647\n",
      "Run: 8540 Loss: 0.1047117115033251\n",
      "Run: 8550 Loss: 0.10471164453290491\n",
      "Run: 8560 Loss: 0.10471157823428759\n",
      "Run: 8570 Loss: 0.10471151260073572\n",
      "Run: 8580 Loss: 0.10471144762557641\n",
      "Run: 8590 Loss: 0.10471138330220348\n",
      "Run: 8600 Loss: 0.10471131962408155\n",
      "Run: 8610 Loss: 0.10471125658473643\n",
      "Run: 8620 Loss: 0.10471119417776342\n",
      "Run: 8630 Loss: 0.10471113239681294\n",
      "Run: 8640 Loss: 0.1047110712356095\n",
      "Run: 8650 Loss: 0.10471101068793495\n",
      "Run: 8660 Loss: 0.10471095074763608\n",
      "Run: 8670 Loss: 0.10471089140861897\n",
      "Run: 8680 Loss: 0.10471083266485254\n",
      "Run: 8690 Loss: 0.10471077451036254\n",
      "Run: 8700 Loss: 0.10471071693924378\n",
      "Run: 8710 Loss: 0.10471065994563754\n",
      "Run: 8720 Loss: 0.10471060352375514\n",
      "Run: 8730 Loss: 0.10471054766785895\n",
      "Run: 8740 Loss: 0.10471049237227426\n",
      "Run: 8750 Loss: 0.10471043763137819\n",
      "Run: 8760 Loss: 0.10471038343960791\n",
      "Run: 8770 Loss: 0.1047103297914523\n",
      "Run: 8780 Loss: 0.1047102766814597\n",
      "Run: 8790 Loss: 0.10471022410423357\n",
      "Run: 8800 Loss: 0.10471017205442522\n",
      "Run: 8810 Loss: 0.10471012052674884\n",
      "Run: 8820 Loss: 0.10471006951596311\n",
      "Run: 8830 Loss: 0.10471001901688451\n",
      "Run: 8840 Loss: 0.10470996902437878\n",
      "Run: 8850 Loss: 0.10470991953336597\n",
      "Run: 8860 Loss: 0.1047098705388163\n",
      "Run: 8870 Loss: 0.1047098220357442\n",
      "Run: 8880 Loss: 0.10470977401922499\n",
      "Run: 8890 Loss: 0.10470972648437743\n",
      "Run: 8900 Loss: 0.10470967942636582\n",
      "Run: 8910 Loss: 0.10470963284041046\n",
      "Run: 8920 Loss: 0.10470958672177566\n",
      "Run: 8930 Loss: 0.10470954106577247\n",
      "Run: 8940 Loss: 0.1047094958677602\n",
      "Run: 8950 Loss: 0.10470945112314287\n",
      "Run: 8960 Loss: 0.10470940682737727\n",
      "Run: 8970 Loss: 0.10470936297595583\n",
      "Run: 8980 Loss: 0.1047093195644225\n",
      "Run: 8990 Loss: 0.10470927658836819\n",
      "Run: 9000 Loss: 0.10470923404342013\n",
      "Run: 9010 Loss: 0.10470919192525417\n",
      "Run: 9020 Loss: 0.10470915022958964\n",
      "Run: 9030 Loss: 0.10470910895219035\n",
      "Run: 9040 Loss: 0.10470906808885985\n",
      "Run: 9050 Loss: 0.10470902763544045\n",
      "Run: 9060 Loss: 0.10470898758782572\n",
      "Run: 9070 Loss: 0.1047089479419401\n",
      "Run: 9080 Loss: 0.10470890869375701\n",
      "Run: 9090 Loss: 0.10470886983928816\n",
      "Run: 9100 Loss: 0.10470883137457969\n",
      "Run: 9110 Loss: 0.10470879329572345\n",
      "Run: 9120 Loss: 0.104708755598851\n",
      "Run: 9130 Loss: 0.10470871828012883\n",
      "Run: 9140 Loss: 0.10470868133576207\n",
      "Run: 9150 Loss: 0.10470864476199816\n",
      "Run: 9160 Loss: 0.10470860855511915\n",
      "Run: 9170 Loss: 0.10470857271144159\n",
      "Run: 9180 Loss: 0.10470853722732586\n",
      "Run: 9190 Loss: 0.10470850209916353\n",
      "Run: 9200 Loss: 0.10470846732338283\n",
      "Run: 9210 Loss: 0.1047084328964511\n",
      "Run: 9220 Loss: 0.10470839881486847\n",
      "Run: 9230 Loss: 0.10470836507516819\n",
      "Run: 9240 Loss: 0.1047083316739214\n",
      "Run: 9250 Loss: 0.10470829860773756\n",
      "Run: 9260 Loss: 0.10470826587324904\n",
      "Run: 9270 Loss: 0.10470823346713272\n",
      "Run: 9280 Loss: 0.10470820138609463\n",
      "Run: 9290 Loss: 0.10470816962687103\n",
      "Run: 9300 Loss: 0.10470813818623526\n",
      "Run: 9310 Loss: 0.10470810706099035\n",
      "Run: 9320 Loss: 0.10470807624797553\n",
      "Run: 9330 Loss: 0.10470804574405403\n",
      "Run: 9340 Loss: 0.1047080155461317\n",
      "Run: 9350 Loss: 0.10470798565113279\n",
      "Run: 9360 Loss: 0.104707956056022\n",
      "Run: 9370 Loss: 0.10470792675778728\n",
      "Run: 9380 Loss: 0.10470789775345558\n",
      "Run: 9390 Loss: 0.1047078690400767\n",
      "Run: 9400 Loss: 0.10470784061473033\n",
      "Run: 9410 Loss: 0.10470781247452961\n",
      "Run: 9420 Loss: 0.10470778461661243\n",
      "Run: 9430 Loss: 0.10470775703814642\n",
      "Run: 9440 Loss: 0.10470772973633176\n",
      "Run: 9450 Loss: 0.10470770270838851\n",
      "Run: 9460 Loss: 0.10470767595157424\n",
      "Run: 9470 Loss: 0.10470764946316474\n",
      "Run: 9480 Loss: 0.10470762324047081\n",
      "Run: 9490 Loss: 0.10470759728082644\n",
      "Run: 9500 Loss: 0.10470757158158973\n",
      "Run: 9510 Loss: 0.10470754614015414\n",
      "Run: 9520 Loss: 0.10470752095392735\n",
      "Run: 9530 Loss: 0.10470749602035509\n",
      "Run: 9540 Loss: 0.10470747133689809\n",
      "Run: 9550 Loss: 0.10470744690105013\n",
      "Run: 9560 Loss: 0.10470742271032607\n",
      "Run: 9570 Loss: 0.10470739876226788\n",
      "Run: 9580 Loss: 0.10470737505444137\n",
      "Run: 9590 Loss: 0.10470735158443589\n",
      "Run: 9600 Loss: 0.10470732834986565\n",
      "Run: 9610 Loss: 0.10470730534837114\n",
      "Run: 9620 Loss: 0.10470728257760974\n",
      "Run: 9630 Loss: 0.10470726003527248\n",
      "Run: 9640 Loss: 0.10470723771906441\n",
      "Run: 9650 Loss: 0.104707215626717\n",
      "Run: 9660 Loss: 0.10470719375598471\n",
      "Run: 9670 Loss: 0.10470717210464803\n",
      "Run: 9680 Loss: 0.10470715067050207\n",
      "Run: 9690 Loss: 0.10470712945136891\n",
      "Run: 9700 Loss: 0.10470710844509289\n",
      "Run: 9710 Loss: 0.10470708764953573\n",
      "Run: 9720 Loss: 0.10470706706258842\n",
      "Run: 9730 Loss: 0.10470704668215672\n",
      "Run: 9740 Loss: 0.10470702650616581\n",
      "Run: 9750 Loss: 0.10470700653256786\n",
      "Run: 9760 Loss: 0.10470698675933234\n",
      "Run: 9770 Loss: 0.1047069671844505\n",
      "Run: 9780 Loss: 0.10470694780592868\n",
      "Run: 9790 Loss: 0.10470692862180132\n",
      "Run: 9800 Loss: 0.10470690963011384\n",
      "Run: 9810 Loss: 0.1047068908289404\n",
      "Run: 9820 Loss: 0.10470687221636846\n",
      "Run: 9830 Loss: 0.10470685379050505\n",
      "Run: 9840 Loss: 0.10470683554947863\n",
      "Run: 9850 Loss: 0.10470681749143272\n",
      "Run: 9860 Loss: 0.10470679961453433\n",
      "Run: 9870 Loss: 0.10470678191696477\n",
      "Run: 9880 Loss: 0.10470676439692611\n",
      "Run: 9890 Loss: 0.10470674705263744\n",
      "Run: 9900 Loss: 0.10470672988233304\n",
      "Run: 9910 Loss: 0.10470671288427373\n",
      "Run: 9920 Loss: 0.10470669605672378\n",
      "Run: 9930 Loss: 0.10470667939797947\n",
      "Run: 9940 Loss: 0.10470666290634337\n",
      "Run: 9950 Loss: 0.1047066465801428\n",
      "Run: 9960 Loss: 0.10470663041771244\n",
      "Run: 9970 Loss: 0.10470661441741617\n",
      "Run: 9980 Loss: 0.10470659857762202\n",
      "Run: 9990 Loss: 0.104706582896723\n",
      "[0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.44350347114989486, 0.44350347114989486, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.6384969798763911, 0.2485099624233985, 0.44350347114989486, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.44350347114989486, 0.6384969798763911, 0.6384969798763911, 0.6384969798763911, 0.44350347114989486, 0.44350347114989486, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.6384969798763911, 0.2485099624233985, 0.2485099624233985, 0.2485099624233985]\n"
     ]
    }
   ],
   "source": [
    "input = read_and_format_data(DATASET_NAME)\n",
    "target = read_and_format_data(\"test.csv\")\n",
    "column = \"Pclass\"\n",
    "x = []\n",
    "y = []\n",
    "test_input = []\n",
    "test_output = []\n",
    "for i in range(len(input[column])):\n",
    "    x.append(input[column][i])\n",
    "for i in range(len(input[\"Survived\"])):\n",
    "    y.append(input[\"Survived\"][i])\n",
    "for i in range(len(target[column])):\n",
    "    test_input.append(target[column][i])\n",
    "    \n",
    "w, b = gradient_descent(x ,y, 0, 0, 10000)\n",
    "\n",
    "for i in test_input:\n",
    "    pred = w * i + b\n",
    "    test_output.append(pred)\n",
    "print(test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
